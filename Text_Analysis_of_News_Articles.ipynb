{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KZkRBtVzd1Ky"
      },
      "outputs": [],
      "source": [
        "#importing libs\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.probability import FreqDist\n",
        "from nltk import bigrams"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the 'punkt' resource\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZobrEUn8nhey",
        "outputId": "d019407c-1738-4775-e8b2-94cdcb021f3f"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/NLP_tokenizer/articles1.csv')"
      ],
      "metadata": {
        "id": "eJtDrtkhlqmS"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Implement a word tokenizer\n",
        "def custom_tokenizer(text):\n",
        "    tokens = word_tokenize(text)\n",
        "    return tokens"
      ],
      "metadata": {
        "id": "cEysf73AmCKJ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize the entire corpus\n",
        "corpus_tokens = [token for text in df['content'].astype(str) for token in custom_tokenizer(text)]"
      ],
      "metadata": {
        "id": "Js03mGvNmaja"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The first 10 lines of the  corpus\n",
        "print(\"First 10 lines of the corpus:\")\n",
        "print(corpus_tokens[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ADowne2qAUp",
        "outputId": "afa7b275-c73a-4eb8-fa44-64170c7b6cbf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 10 lines of the corpus:\n",
            "['WASHINGTON', 'â€”', 'Congressional', 'Republicans', 'have', 'a', 'new', 'fear', 'when', 'it']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Total number of tokens and types in the corpus\n",
        "total_tokens = len(corpus_tokens)\n",
        "total_types = len(set(corpus_tokens))\n",
        "print(\"Total number of tokens:\", total_tokens)\n",
        "print(\"Total number of types :\", total_types)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cT59gL4qF7w",
        "outputId": "53626f11-b5bd-48b3-a780-dd3024bb5d83"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of tokens: 38222245\n",
            "Total number of types : 226908\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Type/token ratio for the corpus\n",
        "token_ratio = total_types / total_tokens\n",
        "print(\"Token Ratio:\", token_ratio)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSnivSY8zjqS",
        "outputId": "8a1298cf-e892-4fac-d8f3-5becd74fd879"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token Ratio: 0.005936542973862472\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A list of the top 3 most frequent tokens\n",
        "freq_dist = FreqDist(corpus_tokens)\n",
        "top_3= freq_dist.most_common(3)\n",
        "print(\"Top 3 Most Frequent Tokens:\", top_3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bqt_zg0I5BP_",
        "outputId": "0a5aae9b-eebe-46b5-a9ba-23ca84d56d54"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 Most Frequent Tokens: [(',', 1859063), ('the', 1662375), ('.', 1457522)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Number of tokens that appeared once\n",
        "appeared_once = len([token for token, freq in freq_dist.items() if freq == 1])\n",
        "print(\"Number of Tokens Appeared Only Once:\", appeared_once)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "meS6PpUn5Clf",
        "outputId": "524bb1bb-dc2a-49ff-8254-0495467d0207"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Tokens Appeared Only Once: 89887\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#A list of the top 3 most frequent words\n",
        "filtered_words = [word.lower() for word in corpus_tokens if word.isalpha()]\n",
        "freq_dist_words = FreqDist(filtered_words)\n",
        "top_three = freq_dist_words.most_common(3)\n",
        "print(\"Top 3 Most Frequent Words:\", top_three)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6pVvfR05Jug",
        "outputId": "a9c0bd13-7f02-457c-efd5-89aef201af1c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 Most Frequent Words: [('the', 1873736), ('to', 891302), ('of', 810486)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lexical Diversity\n",
        "lexical_Diversity = len(set(filtered_words)) / len(filtered_words)\n",
        "print(\"Lexical devsity  :\", lexical_Diversity )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhU7yTrs5u95",
        "outputId": "d4f79b43-d2ca-460e-8531-ac4da97774df"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lexical devsity  : 0.0052486779677832635\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InxmPakCG2b4",
        "outputId": "ac405e0b-f96a-4e95-f8fa-6d11fb5aa196"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#list of the top 3 most frequent words (excluding stopwords and punctuation)\n",
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_stopwords = [word for word in filtered_words if word not in stop_words]\n",
        "freq_dist_stopwords = FreqDist(filtered_stopwords)\n",
        "top_three_stopwords = freq_dist_stopwords.most_common(3)\n",
        "print(\"Top 3 Most Frequent Words (excluding stopwords):\", top_three_stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9krHxKzGZLI",
        "outputId": "17735274-f887-47a8-8fc8-4ecb2294cc27"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 Most Frequent Words (excluding stopwords): [('said', 207527), ('trump', 149726), ('people', 77330)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " #Lexical density ( without stopwords)\n",
        "lexical_density= len(set(filtered_stopwords)) / len(filtered_stopwords)\n",
        "print(\"lexical_density  :\", lexical_density )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bRWAIA6Hrmx",
        "outputId": "1e4ba196-568e-4425-8f88-c3d3d6842d14"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lexical_density  : 0.00957795115795021\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  list of the most frequent 3 bigrams\n",
        "corpus_bigrams = list(bigrams(filtered_words))\n",
        "freq_dist_bigrams = FreqDist(corpus_bigrams)\n",
        "top_three = freq_dist_bigrams.most_common(3)\n",
        "print(\"Top 3 Most Frequent Bigrams \", top_three)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWos_gk77Xk_",
        "outputId": "347ee1d0-cafa-452b-a10d-176fec5d3fa2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 Most Frequent Bigrams  [(('of', 'the'), 193629), (('in', 'the'), 159726), (('to', 'the'), 89586)]\n"
          ]
        }
      ]
    }
  ]
}